{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling\n",
        "### `! git clone https://github.com/ds3001f25/wrangling_assignment.git`\n",
        "### Do Q1 and Q2\n",
        "### Reading material: `tidy_data.pdf`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q1.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the Minnesota police use of for data, `./data/mn_police_use_of_force.csv`, clean the `subject_injury` variable, handling the NA's; this gives a value `Yes` when a person was injured by police, and `No` when no injury occurred. What proportion of the values are missing? Is this a concern? Cross-tabulate your cleaned `subject_injury` variable with the `force_type` variable. Are there any patterns regarding when the data are missing?\n",
        "3. Dummy variable: For the pretrial data covered in the lecture `./data/justice_data.parquet`, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d412a8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "9d412a8d",
        "outputId": "a7bada32-d7d8-4c3a-ada3-2c00185fc46a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/airbnb_hw.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1616681867.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the Airbnb data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mairbnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/airbnb_hw.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Look at the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/airbnb_hw.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Airbnb data\n",
        "airbnb = pd.read_csv(\"./data/airbnb_hw.csv\")\n",
        "\n",
        "# Look at the first few rows\n",
        "airbnb.head()\n",
        "\n",
        "# Clean the Price column\n",
        "# - Remove $ signs and commas\n",
        "# - Convert to numeric\n",
        "airbnb[\"Price_clean\"] = (\n",
        "    airbnb[\"Price\"]\n",
        "    .str.replace(\"$\", \"\", regex=False)\n",
        "    .str.replace(\",\", \"\", regex=False)\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# Check missing values\n",
        "missing_count = airbnb[\"Price_clean\"].isna().sum()\n",
        "print(\"Number of missing values in Price_clean:\", missing_count)\n",
        "\n",
        "# Show a summary of the cleaned column\n",
        "airbnb[\"Price_clean\"].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f03830",
      "metadata": {
        "id": "a3f03830"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0d71335",
        "outputId": "8d6e8c63-ef37-4939-8c30-61f300f215b1"
      },
      "source": [
        "# Clone the repository to access the data\n",
        "!git clone https://github.com/ds3001f25/wrangling_assignment.git"
      ],
      "id": "d0d71335",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wrangling_assignment'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 8 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11/11), 5.83 MiB | 14.82 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "1e376bbf",
        "outputId": "13b34929-a272-4a1f-9886-da96bffbe21b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Airbnb data - updating the path after cloning\n",
        "airbnb = pd.read_csv(\"./wrangling_assignment/data/airbnb_hw.csv\")\n",
        "\n",
        "# Look at the first few rows\n",
        "airbnb.head()\n",
        "\n",
        "# Clean the Price column\n",
        "# - Remove $ signs and commas\n",
        "# - Convert to numeric\n",
        "airbnb[\"Price_clean\"] = (\n",
        "    airbnb[\"Price\"]\n",
        "    .str.replace(\"$\", \"\", regex=False)\n",
        "    .str.replace(\",\", \"\", regex=False)\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# Check missing values\n",
        "missing_count = airbnb[\"Price_clean\"].isna().sum()\n",
        "print(\"Number of missing values in Price_clean:\", missing_count)\n",
        "\n",
        "# Show a summary of the cleaned column\n",
        "airbnb[\"Price_clean\"].describe()"
      ],
      "id": "1e376bbf",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values in Price_clean: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    30478.000000\n",
              "mean       163.589737\n",
              "std        197.785454\n",
              "min         10.000000\n",
              "25%         80.000000\n",
              "50%        125.000000\n",
              "75%        195.000000\n",
              "max      10000.000000\n",
              "Name: Price_clean, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30478.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>163.589737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>197.785454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>125.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>195.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaned the Price column by:\n",
        "\n",
        "Removing $ signs and commas.\n",
        "\n",
        "Converting it to numbers so Python can calculate with it.\n",
        "\n",
        "Checking how many values are missing."
      ],
      "metadata": {
        "id": "MzB43qC1D-dC"
      },
      "id": "MzB43qC1D-dC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Minnesota police data\n",
        "df2 = pd.read_csv(\"./data/mn_police_use_of_force.csv\")\n",
        "\n",
        "# Clean the subject_injury column\n",
        "df2['subject_injury_clean'] = (\n",
        "    df2['subject_injury']\n",
        "    .str.strip()\n",
        "    .str.capitalize()\n",
        "    .replace({'Nan': pd.NA, '': pd.NA})\n",
        ")\n",
        "\n",
        "# Calculate missing proportion\n",
        "missing_count_mean = df2['subject_injury_clean'].isna().mean()\n",
        "print(f\"Proportion missing: {missing_count_mean:.2%}\")\n",
        "\n",
        "# Cross-tabulate with force_type\n",
        "ct = pd.crosstab(df2['subject_injury_clean'], df2['force_type'], dropna=False)\n",
        "print(ct)"
      ],
      "metadata": {
        "id": "HLQ8xRDLEBHE"
      },
      "id": "HLQ8xRDLEBHE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "emoving extra spaces.\n",
        "\n",
        "Making text consistent (capitalize first letter).\n",
        "\n",
        "Marking blank values as missing"
      ],
      "metadata": {
        "id": "V-BtZMdZERMh"
      },
      "id": "V-BtZMdZERMh"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "justice = pd.read_parquet(\"./data/justice_data.parquet\", engine=\"fastparquet\")\n",
        "\n",
        "# Clean release column\n",
        "justice['released_clean'] = (\n",
        "    justice['WhetherDefendantWasReleasedPretrial']\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        ")\n",
        "\n",
        "justice['released_clean'] = justice['released_clean'].replace({\n",
        "    'yes': 'Yes',\n",
        "    'y': 'Yes',\n",
        "    'released': 'Yes',\n",
        "    'no': 'No',\n",
        "    'n': 'No',\n",
        "    'not released': 'No',\n",
        "    'nan': np.nan,\n",
        "    '': np.nan,\n",
        "})\n",
        "\n",
        "justice['released_dummy'] = justice['released_clean'].map({'Yes': 1, 'No': 0})\n"
      ],
      "metadata": {
        "id": "ok7Jvak4EWvs"
      },
      "id": "ok7Jvak4EWvs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making all answers lowercase first.\n",
        "\n",
        "Mapping different ways of saying “Yes” or “No” to standard Yes/No.\n",
        "\n",
        "Creating a new column released_dummy with 1 for Yes, 0 for No, which is easier for analysis"
      ],
      "metadata": {
        "id": "FGkE5EiCEdGI"
      },
      "id": "FGkE5EiCEdGI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ImposedSentence column to numeric\n",
        "justice['imposed_sentence_clean'] = pd.to_numeric(\n",
        "    justice['ImposedSentenceAllChargeInContactEvent'], errors='coerce'\n",
        ")\n",
        "\n",
        "missing_count = justice['imposed_sentence_clean'].isna().sum()\n",
        "total_count = len(justice)\n",
        "missing_prop = missing_count / total_count\n",
        "print(f\"Missing values: {missing_count} ({missing_prop:.2%})\")\n"
      ],
      "metadata": {
        "id": "v6RZ-DHhEd9b"
      },
      "id": "v6RZ-DHhEd9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaned sentence lengths by converting to numbers and keeping missing values as missing"
      ],
      "metadata": {
        "id": "SgOGaqdaE1yY"
      },
      "id": "SgOGaqdaE1yY"
    },
    {
      "cell_type": "markdown",
      "id": "5a60a44e",
      "metadata": {
        "id": "5a60a44e"
      },
      "source": [
        "**Q2.** Go to https://sharkattackfile.net/ and download their dataset on shark attacks (Hint: `GSAF5.xls`).\n",
        "\n",
        "1. Open the shark attack file using Pandas. It is probably not a csv file, so `read_csv` won't work.\n",
        "2. Drop any columns that do not contain data.\n",
        "3. Clean the year variable. Describe the range of values you see. Filter the rows to focus on attacks since 1940. Are attacks increasing, decreasing, or remaining constant over time?\n",
        "4. Clean the Age variable and make a histogram of the ages of the victims.\n",
        "5. What proportion of victims are male?\n",
        "6. Clean the `Type` variable so it only takes three values: Provoked and Unprovoked and Unknown. What proportion of attacks are unprovoked?\n",
        "7. Clean the `Fatal Y/N` variable so it only takes three values: Y, N, and Unknown.\n",
        "8. Are sharks more likely to launch unprovoked attacks on men or women? Is the attack more or less likely to be fatal when the attack is provoked or unprovoked? Is it more or less likely to be fatal when the victim is male or female? How do you feel about sharks?\n",
        "9. What proportion of attacks appear to be by white sharks? (Hint: `str.split()` makes a vector of text values into a list of lists, split by spaces.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "df = pd.read_excel(\"./data/GSAF5.xls\")\n",
        "\n",
        "# Drop columns that are completely empty\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Look at first few rows\n",
        "df.head()\n",
        "##"
      ],
      "metadata": {
        "id": "qG-RI6wRFaLZ"
      },
      "id": "qG-RI6wRFaLZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "71Tk299XFdUF"
      },
      "id": "71Tk299XFdUF"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert Year column to numbers\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "\n",
        "# Filter attacks from 1940 onwards\n",
        "df_1940 = df[df['Year'] >= 1940]\n",
        "\n",
        "# Count attacks per year\n",
        "attacks_per_year = df_1940['Year'].value_counts().sort_index()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,5))\n",
        "attacks_per_year.plot()\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of attacks\")\n",
        "plt.title(\"Shark attacks since 1940\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A6gqXgKXFc5x"
      },
      "id": "A6gqXgKXFc5x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "made the Year column numeric so we can filter by year then looked at attacks since 1940 and plotted them to see trends over time.\n",
        "\n",
        "Observation: Shark attacks seem to generally increase over time, but events like COVID caused big drops."
      ],
      "metadata": {
        "id": "iiQPso4mFoq2"
      },
      "id": "iiQPso4mFoq2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Age to numeric\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "\n",
        "# Drop missing ages\n",
        "ages = df['Age'].dropna()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(ages, bins=20, edgecolor='black')\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Histogram of victim ages\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o1c6jJonFsyX"
      },
      "id": "o1c6jJonFsyX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converted ages to numbers and dropped missing values.\n",
        "The histogram shows the distribution of victim ages."
      ],
      "metadata": {
        "id": "wvtj4XlGFwFE"
      },
      "id": "wvtj4XlGFwFE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize Sex column\n",
        "df['Sex'] = df['Sex'].str.upper().replace({'M': 'M', 'F': 'F'})\n",
        "\n",
        "# Calculate proportion of males\n",
        "male_prop = (df['Sex'] == 'M').mean()\n",
        "print(f\"Proportion of male victims: {male_prop:.2%}\")\n"
      ],
      "metadata": {
        "id": "Z6w_KuokF0UO"
      },
      "id": "Z6w_KuokF0UO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c8DZeCYKF2jW"
      },
      "id": "c8DZeCYKF2jW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Type column\n",
        "def clean_type(type_val):\n",
        "    if pd.isna(type_val):\n",
        "        return 'Unknown'\n",
        "    type_str = str(type_val).upper().strip()\n",
        "    if 'UNPROVOKED' in type_str:\n",
        "        return 'Unprovoked'\n",
        "    elif 'PROVOKED' in type_str:\n",
        "        return 'Provoked'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "df['Type_Clean'] = df['Type'].apply(clean_type)\n",
        "\n",
        "# Proportion unprovoked\n",
        "type_counts = df['Type_Clean'].value_counts()\n",
        "print(f\"Proportion of attacks that are unprovoked: {type_counts.get('Unprovoked', 0) / len(df):.1%}\")\n"
      ],
      "metadata": {
        "id": "ZffQ-i5_F5lY"
      },
      "id": "ZffQ-i5_F5lY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "standardized attack types into three categories: Provoked, Unprovoked, and Unknown.\n",
        "About 74% of attacks are unprovoked."
      ],
      "metadata": {
        "id": "Sq_etMKeF95d"
      },
      "id": "Sq_etMKeF95d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Fatal Y/N column\n",
        "def clean_fatal(fatal_val):\n",
        "    if pd.isna(fatal_val):\n",
        "        return 'Unknown'\n",
        "    fatal_str = str(fatal_val).upper().strip()\n",
        "    if fatal_str in ['Y', 'YES']:\n",
        "        return 'Y'\n",
        "    elif fatal_str in ['N', 'NO']:\n",
        "        return 'N'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "df['Fatal_Clean'] = df['Fatal Y/N'].apply(clean_fatal)\n"
      ],
      "metadata": {
        "id": "72xi-96aF-b4"
      },
      "id": "72xi-96aF-b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unprovoked attacks by sex\n",
        "unprovoked = df[df['Type_Clean'] == 'Unprovoked']\n",
        "ct_sex = pd.crosstab(unprovoked['Sex'], unprovoked['Type_Clean'], normalize='columns')\n",
        "print(\"Proportion of unprovoked attacks by sex:\")\n",
        "print(ct_sex)\n",
        "\n",
        "# Fatality by attack type\n",
        "ct_fatal_type = pd.crosstab(df['Type_Clean'], df['Fatal_Clean'], normalize='index')\n",
        "print(\"\\nFatality rate by attack type:\")\n",
        "print(ct_fatal_type)\n",
        "\n",
        "# Fatality by sex\n",
        "ct_fatal_sex = pd.crosstab(df['Sex'], df['Fatal_Clean'], normalize='index')\n",
        "print(\"\\nFatality rate by sex:\")\n",
        "print(ct_fatal_sex)\n"
      ],
      "metadata": {
        "id": "21aho1fIGBX-"
      },
      "id": "21aho1fIGBX-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compared - Unprovoked attacks by male vs female victims.\n",
        "\n",
        "Fatality rates depending on attack type.\n",
        "\n",
        "Fatality rates by victim sex.\n",
        "\n",
        "Observation: Men are more often victims of unprovoked attacks. Provoked attacks are slightly more deadly, but both types are generally low. Fatality is roughly equal for men and women."
      ],
      "metadata": {
        "id": "kPmHFqGPGGV1"
      },
      "id": "kPmHFqGPGGV1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Species column\n",
        "df['Species '] = df['Species '].str.upper().fillna('UNKNOWN')\n",
        "\n",
        "# Proportion of attacks by white sharks\n",
        "white_shark_attacks = df['Species '].str.contains('WHITE', na=False).mean()\n",
        "print(f\"Proportion of attacks by white sharks: {white_shark_attacks:.2%}\")\n"
      ],
      "metadata": {
        "id": "DFbMI3KpGQeF"
      },
      "id": "DFbMI3KpGQeF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About 10.7% of attacks are caused by white sharks."
      ],
      "metadata": {
        "id": "P0iG7LVKGa5d"
      },
      "id": "P0iG7LVKGa5d"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}